{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# What is Handwritten Digit Recognition?\nHandwritten digit recognition is the ability of computers to recognize human handwritten digits. It is a hard task for the machine because handwritten digits are not perfect and can vary from person to person. Handwritten digit recognition is the solution to this problem which uses the image of a digit and recognizes the digit present in the image.","metadata":{}},{"cell_type":"markdown","source":"# About the Dataset\n\nThis dataset is inspired by the MNIST database for handwritten digits. It consists of images representing digits from 0-9 produced using 2,990 google fonts files.\n\nThe dataset consists of a single file:\n\nTMNIST_Data.csv\n\nThis file consists of 29,900 examples with labels and font names. Each row contains 786 elements: the first element represents the font name (ex-Chivo-Italic, Sen-Bold), the second element represents the label (a number from 0-9) and the remaining 784 elements represent the grayscale pixel values (from 0-255) for the 28x28 pixel image.\n\n","metadata":{}},{"cell_type":"markdown","source":"# What is Convolutional Neural Network\n\nA Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm that can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image, and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics.\n\nA ConvNet's architecture is influenced by how the Visual Cortex is organised and is similar to the connectivity network of neurons in the human brain. While there are many complex CNN architectures like Resnet, Inception V3 and so on designed to achieve state-of-the-art performance on real world images, in this tutorial, we will create a custom Convolutional Neural Network Architecture using Pytorch.\n\nWe will be training and testing our model on the Typeface MNIST Dataset, which consists of over 29,000 samples of images of 0-9 digits in various fonts along with their labels.","metadata":{}},{"cell_type":"markdown","source":"#                          Architecture of Neural Network\n\n<img src= \"https://upload.wikimedia.org/wikipedia/commons/b/b6/Artificial_neural_network.png\" alt =\"Titanic\" style='width: 700px;'>\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"This notebook is further divided into the following sections.\n\n- Importing required Libraries\n- Loading the dataset\n- Creating a CNN Model\n- Training our model\n- Evaluating our model","metadata":{}},{"cell_type":"markdown","source":"# Importing All necessary librarirs","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n#import pytorch\nimport torch\n\n# torch functionalities used for building our CNN Model\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torch.utils.data as data_utils","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:32.135608Z","iopub.execute_input":"2023-04-16T19:09:32.136434Z","iopub.status.idle":"2023-04-16T19:09:34.921592Z","shell.execute_reply.started":"2023-04-16T19:09:32.136387Z","shell.execute_reply":"2023-04-16T19:09:34.920250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:34.924264Z","iopub.execute_input":"2023-04-16T19:09:34.925329Z","iopub.status.idle":"2023-04-16T19:09:35.515000Z","shell.execute_reply.started":"2023-04-16T19:09:34.925276Z","shell.execute_reply":"2023-04-16T19:09:35.513533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How to train your neural net faster?\nWe saw that the computationally intensive part of neural network is made up of multiple matrix multiplications. So how can we make it faster?","metadata":{}},{"cell_type":"markdown","source":"Since we will be building a CNN model, a GPU is required to speed up the training process. Before starting with the implementation, we verify the presence of an active GPU and set the device accordingly.","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:35.516861Z","iopub.execute_input":"2023-04-16T19:09:35.517744Z","iopub.status.idle":"2023-04-16T19:09:35.523986Z","shell.execute_reply.started":"2023-04-16T19:09:35.517646Z","shell.execute_reply":"2023-04-16T19:09:35.522584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Reading data into pandas dataframe.\n#data_path = \"/kaggle/input/94-character-tmnist/94_character_TMNIST.csv\"\ndata_path = \"/kaggle/input/tmnist-typeface-mnist/TMNIST_Data.csv\"\ndata = pd.read_csv(data_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:35.526772Z","iopub.execute_input":"2023-04-16T19:09:35.527600Z","iopub.status.idle":"2023-04-16T19:09:38.309572Z","shell.execute_reply.started":"2023-04-16T19:09:35.527558Z","shell.execute_reply":"2023-04-16T19:09:38.308070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performing EDA","metadata":{}},{"cell_type":"code","source":"#A view of dataset.\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:38.311434Z","iopub.execute_input":"2023-04-16T19:09:38.311993Z","iopub.status.idle":"2023-04-16T19:09:38.356761Z","shell.execute_reply.started":"2023-04-16T19:09:38.311927Z","shell.execute_reply":"2023-04-16T19:09:38.355042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining Shape and Number of Sample in the Dataset\nprint(f\"The Shape of the Dataframe is: {data.shape}\") #Number of Samples, Number of Pixels(Features)\nprint(f\"Number of Samples: {data.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:38.358449Z","iopub.execute_input":"2023-04-16T19:09:38.358966Z","iopub.status.idle":"2023-04-16T19:09:38.367630Z","shell.execute_reply.started":"2023-04-16T19:09:38.358912Z","shell.execute_reply":"2023-04-16T19:09:38.365735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of unique character in the Dataframe\nprint(f\"Number of unique character present in the Dataset: {len(data.labels.unique())}\") #Number of Classes\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:38.369210Z","iopub.execute_input":"2023-04-16T19:09:38.369656Z","iopub.status.idle":"2023-04-16T19:09:38.398117Z","shell.execute_reply.started":"2023-04-16T19:09:38.369616Z","shell.execute_reply":"2023-04-16T19:09:38.396352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label distribution\ndata.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:38.399986Z","iopub.execute_input":"2023-04-16T19:09:38.400417Z","iopub.status.idle":"2023-04-16T19:09:38.412507Z","shell.execute_reply.started":"2023-04-16T19:09:38.400379Z","shell.execute_reply":"2023-04-16T19:09:38.411042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We observe that the labels are equally distributed with 2990 instances of each class. Hence, our dataset is balanced.\n\nNow, let us reshape and modify our data so that it can be used as an input for our model. We normalise the data and reshape it into a 4 dimensional array such that it represents images stacked on to each other. We also reshape our labels into a 1 dimensional array.","metadata":{}},{"cell_type":"code","source":"#Dropping redundant coloums like names and labels from the training frames and keeping only pixel values\nX = data.drop(columns = {'names', 'labels'})/255\nX = X.values.reshape(X.shape[0], 1, 28, 28)\ny = data[['labels']].values.reshape((-1,))","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:38.414389Z","iopub.execute_input":"2023-04-16T19:09:38.414796Z","iopub.status.idle":"2023-04-16T19:09:38.575720Z","shell.execute_reply.started":"2023-04-16T19:09:38.414759Z","shell.execute_reply":"2023-04-16T19:09:38.574487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before proceeding, we split our data into training and testing sets using an 80:20 proportion.","metadata":{}},{"cell_type":"code","source":"#split data into training and testing sets using the train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:38.581454Z","iopub.execute_input":"2023-04-16T19:09:38.581830Z","iopub.status.idle":"2023-04-16T19:09:38.883854Z","shell.execute_reply.started":"2023-04-16T19:09:38.581794Z","shell.execute_reply":"2023-04-16T19:09:38.882343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now convert them to numpy arrays so that they can be further worked with.","metadata":{}},{"cell_type":"code","source":"# Convert X_train, X_test, y_train, and y_test to PyTorch tensors\nX_train = torch.from_numpy(X_train)\nX_test = torch.from_numpy(X_test)\ny_train = torch.from_numpy(y_train)\ny_test = torch.from_numpy(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:38.885432Z","iopub.execute_input":"2023-04-16T19:09:38.885939Z","iopub.status.idle":"2023-04-16T19:09:38.901876Z","shell.execute_reply.started":"2023-04-16T19:09:38.885902Z","shell.execute_reply":"2023-04-16T19:09:38.900335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before proceeding, we split our data into training and testing sets using an 80:20 proportion.","metadata":{}},{"cell_type":"code","source":"#printing shape\nprint(X_train.shape, y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:38.904297Z","iopub.execute_input":"2023-04-16T19:09:38.904685Z","iopub.status.idle":"2023-04-16T19:09:38.917780Z","shell.execute_reply.started":"2023-04-16T19:09:38.904649Z","shell.execute_reply":"2023-04-16T19:09:38.916453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We verify our steps by checking the shape of our newly created torch tensors.\n\nNow, let us visualise a sample image from our processed data.","metadata":{}},{"cell_type":"code","source":"\ndef visualize_image(data):\n    # Display the image using matplotlib's imshow() function\n    plt.imshow(data[0], cmap='gray_r')\n    # Turn off the axis display in the plot\n    plt.axis(\"off\")\n    # Show the plot with the displayed image\n    plt.show()\n\n# Call the visualize_image() function with the first image in X_train dataset\nvisualize_image(X_train[0])\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:38.919681Z","iopub.execute_input":"2023-04-16T19:09:38.920014Z","iopub.status.idle":"2023-04-16T19:09:39.068328Z","shell.execute_reply.started":"2023-04-16T19:09:38.919981Z","shell.execute_reply":"2023-04-16T19:09:39.066212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Create a CNN Model\nCreate Data Loader\nDataloaders are utilized to feed our input data to our model for training, based on different parameters such as the batch size, if they should be suffled while being fed, and so on.\n\nHere, we define our tensordatasets for the dataloader and then input our required parameters to prepare the data loaders.","metadata":{}},{"cell_type":"code","source":"print(type(X_train))\nprint(type(y_train))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:39.071671Z","iopub.execute_input":"2023-04-16T19:09:39.073215Z","iopub.status.idle":"2023-04-16T19:09:39.084487Z","shell.execute_reply.started":"2023-04-16T19:09:39.073113Z","shell.execute_reply":"2023-04-16T19:09:39.082416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a training dataset from X_train and y_train\ntrain = data_utils.TensorDataset(X_train, y_train)\n# Create a testing dataset from X_test and y_test\ntest = data_utils.TensorDataset(X_test, y_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:39.088464Z","iopub.execute_input":"2023-04-16T19:09:39.090188Z","iopub.status.idle":"2023-04-16T19:09:39.102772Z","shell.execute_reply.started":"2023-04-16T19:09:39.090087Z","shell.execute_reply":"2023-04-16T19:09:39.100492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once you have created your TensorDataset objects, you can pass them to data loaders in PyTorch to efficiently load and preprocess your data during model training or testing. Data loaders allow you to iterate over your dataset in batches, shuffle the data, and apply other data augmentation techniques as needed","metadata":{}},{"cell_type":"code","source":"\n# Create a training data loader from the train dataset\n# with a batch size of 128 and shuffling the data\ntrain_loader = data_utils.DataLoader(train, batch_size=128, shuffle=True)\n\n# Create a testing data loader from the test dataset\n# with a batch size of 128 and shuffling the data\ntest_loader = data_utils.DataLoader(test, batch_size=128, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:39.106752Z","iopub.execute_input":"2023-04-16T19:09:39.108776Z","iopub.status.idle":"2023-04-16T19:09:39.120576Z","shell.execute_reply.started":"2023-04-16T19:09:39.108675Z","shell.execute_reply":"2023-04-16T19:09:39.118423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To verify our data loaders, we print the input size of an iteration of training.","metadata":{}},{"cell_type":"code","source":"#printing input size of an iteration of training\nfor images, labels in train_loader:\n    print(images.shape, labels.shape)\n\ndata_iter = iter(train_loader)\nimages, labels = next(data_iter)\nprint(images.shape, labels.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:39.122401Z","iopub.execute_input":"2023-04-16T19:09:39.123033Z","iopub.status.idle":"2023-04-16T19:09:39.412512Z","shell.execute_reply.started":"2023-04-16T19:09:39.122978Z","shell.execute_reply":"2023-04-16T19:09:39.411021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3)     # First convolutional layer with input channels=1, output channels=32, and kernel size=3x3\n        self.conv2 = nn.Conv2d(32, 64, 3)    # Second convolutional layer with input channels=32, output channels=64, and kernel size=3x3\n        self.pool = nn.MaxPool2d(2, 2)       # Max pooling layer with kernel size=2x2 and stride=2\n        self.fc1 = nn.Linear(64 * 12 * 12, 128)  # Fully connected layer with input size of 64x12x12 (output from previous layers) and output size of 128\n        self.fc2 = nn.Linear(128, 10)        # Fully connected layer with input size of 128 and output size of 10 (for 10 classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))            # Apply ReLU activation to the output of the first convolutional layer\n        x = self.pool(F.relu(self.conv2(x))) # Apply ReLU activation to the output of the second convolutional layer, then perform max pooling\n        x = x.view(-1, 64 * 12 * 12)         # Flatten the tensor to a 1D vector\n        x = F.relu(self.fc1(x))              # Apply ReLU activation to the output of the first fully connected layer\n        x = self.fc2(x)                      # Output from the second fully connected layer (logits)\n        return x\n\nnet = Net()                               # Create an instance of the neural network model\nnet.to(device)                           # Move the model to the specified device (e.g., GPU or CPU)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:39.414202Z","iopub.execute_input":"2023-04-16T19:09:39.415385Z","iopub.status.idle":"2023-04-16T19:09:39.448714Z","shell.execute_reply.started":"2023-04-16T19:09:39.415343Z","shell.execute_reply":"2023-04-16T19:09:39.447334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model\n\n- Convolution layer (CONV)- The convolution layer (CONV) uses filters that perform convolution operations as it is scanning the input I with respect to its dimensions. Its hyperparameters include the filter size F and stride S. The resulting output O is called feature map or activation map.\n- Pooling (POOL)- The pooling layer (POOL) is a downsampling operation, typically applied after a convolution layer, which does some spatial invariance. In particular, max and average pooling are special kinds of pooling where the maximum and average value is taken, respectively.\n\nTo create our CNN Model, we utilise the neural network module from pytorch and provide it with our own custom architecture as follows.\n\n- Convolutional layer with 32 channels\n- Convolutional layer with 64 channels\n- MaxPooling layer to compress information\n- Dense layer to flatten the information obtained\n- Dense output layer with relu activation","metadata":{}},{"cell_type":"markdown","source":"We use Cross Entropy Loss as the loss function and Adam as the optimizer here. You can also try out other optimizers like SGD here ","metadata":{}},{"cell_type":"code","source":"\ncriterion = nn.CrossEntropyLoss()\n#optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)\noptimizer = optim.Adam(net.parameters(), lr = 0.001)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:39.453278Z","iopub.execute_input":"2023-04-16T19:09:39.453670Z","iopub.status.idle":"2023-04-16T19:09:39.460366Z","shell.execute_reply.started":"2023-04-16T19:09:39.453636Z","shell.execute_reply":"2023-04-16T19:09:39.458721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, inorder to deal with input data in the float format, we modify the format of our CNN model net to float.","metadata":{}},{"cell_type":"code","source":"net = net.float()","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:39.462370Z","iopub.execute_input":"2023-04-16T19:09:39.462874Z","iopub.status.idle":"2023-04-16T19:09:39.474760Z","shell.execute_reply.started":"2023-04-16T19:09:39.462834Z","shell.execute_reply":"2023-04-16T19:09:39.473494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model\n\nDefinitions:\n\n- Epoch- In the context of training a model, epoch is a term used to refer to one iteration where the  model sees the whole training set to update its weights.\n\n\n- Mini batch gradient descent- During the training phase, updating weights is usually not based on the  whole training set at once due to computation complexities or one data point due to noise issues. Instead, the update step is done on mini-batches, where the number of data points in a batch is a hyperparameter that we can tune.\n\n\n- Loss function -In order to quantify how a given model performs, the loss function .L is usually used   to evaluate to what extent the actual outputs y are correctly predicted by the model outputs z.\n\n\n- Cross-entropy lossIn the context of binary classification in neural networks, the cross-entropy loss \n L(z,y) is commonly used and is defined as follows:\n\n\nWe now train the model for 15 epochs and print its loss and test accuracy for each 50 completed mini batches. I used 15 epochs as it provided a satisfactory learning curve for this dataset, but feel free to explore with other number as well.","metadata":{}},{"cell_type":"code","source":"epoch_num = 0\nactual_loss = 0.0\naccuracy = 0.0","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:39.475811Z","iopub.execute_input":"2023-04-16T19:09:39.476146Z","iopub.status.idle":"2023-04-16T19:09:39.490283Z","shell.execute_reply.started":"2023-04-16T19:09:39.476114Z","shell.execute_reply":"2023-04-16T19:09:39.488636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training model with 15 epochs\n\nnum_epochs = 15\n\n# Create lists to store epoch number, loss, and accuracy for each epoch\nepoch_log = []\nloss_log = []\naccuracy_log = []\n\nfor epoch in range(num_epochs):\n    print(f'Starting Epoch: {epoch + 1}...')\n\n    running_loss = 0.0   # Initialize running loss to 0 for each epoch\n\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs = inputs.to(device)    # Move inputs to the specified device (e.g., GPU or CPU)\n        labels = labels.to(device)    # Move labels to the specified device\n\n        optimizer.zero_grad()        # Zero the gradients of the optimizer\n\n        outputs = net(inputs.float())   # Forward pass to get predicted outputs from the model\n        loss = criterion(outputs,labels)  # Compute the loss between predicted outputs and ground truth labels\n        loss.backward()                 # Backward pass to compute gradients\n        optimizer.step()                # Update model weights using the optimizer\n\n        running_loss += loss.item()   # Add the current batch loss to the running loss for this epoch\n        if i % 50 == 49:\n            correct = 0\n            total = 0\n            \n            with torch.no_grad():\n                for data in test_loader:\n                    images, labels = data\n                    images = images.to(device)    # Move images to the specified device\n                    labels = labels.to(device)    # Move labels to the specified device\n                    outputs = net(images.float())  # Forward pass to get predicted outputs from the model\n                    \n                    _, predicted = torch.max(outputs.data, dim = 1)   # Get predicted labels with maximum probability\n                    total += labels.size(0)   # Update total number of images\n                    correct += (predicted == labels).sum().item()   # Update correct predictions count\n                \n                accuracy = 100 * correct / total   # Calculate accuracy for this epoch\n                actual_loss = running_loss / 50   # Calculate average loss for this epoch\n                epoch_num = epoch + 1   # Get current epoch number\n                print(f'Epoch: {epoch_num}, Mini-Batches Completed: {(i + 1)}, Loss: {actual_loss:.3f}, Test Accuracy: {accuracy:.3f}%')\n                \n    epoch_log.append(epoch_num)   # Append epoch number to the epoch log\n    loss_log.append(actual_loss)   # Append average loss to the loss log\n    accuracy_log.append(accuracy)   # Append accuracy to the accuracy log\n\n\nprint('Training Completed.')","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:09:39.492519Z","iopub.execute_input":"2023-04-16T19:09:39.492900Z","iopub.status.idle":"2023-04-16T19:18:09.479746Z","shell.execute_reply.started":"2023-04-16T19:09:39.492865Z","shell.execute_reply":"2023-04-16T19:18:09.478330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model\nLet's save our trained model to PATH so that it can be reused.","metadata":{}},{"cell_type":"code","source":"PATH = './cnn_net.pth'\ntorch.save(net.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:18:09.481769Z","iopub.execute_input":"2023-04-16T19:18:09.482525Z","iopub.status.idle":"2023-04-16T19:18:09.498091Z","shell.execute_reply.started":"2023-04-16T19:18:09.482472Z","shell.execute_reply":"2023-04-16T19:18:09.496518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating  Model\nReloading Model\nTo evaluate our trained CNN model, we reload our saved model.","metadata":{}},{"cell_type":"code","source":"net = Net()\nnet.to(device)\nnet.load_state_dict(torch.load(PATH))","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:18:09.500219Z","iopub.execute_input":"2023-04-16T19:18:09.502044Z","iopub.status.idle":"2023-04-16T19:18:09.527480Z","shell.execute_reply.started":"2023-04-16T19:18:09.501984Z","shell.execute_reply":"2023-04-16T19:18:09.525947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How well our model makes prediction with test data?\nNow, let us use our test dataset to determine the final accuracy of our trained model.","metadata":{}},{"cell_type":"code","source":"correct = 0   # Initialize count of correct predictions to 0\ntotal = 0     # Initialize count of total predictions to 0\n\nwith torch.no_grad():   # Disable gradient computation for efficiency\n    for data in test_loader:   # Loop through the test dataset\n        images, labels = data   # Get images and labels from the test dataset\n        images = images.to(device)   # Move images to the specified device (e.g., GPU or CPU)\n        labels = labels.to(device)   # Move labels to the specified device\n        outputs = net(images.float())   # Forward pass to get predicted outputs from the model\n        _, predicted = torch.max(outputs.data, 1)   # Get predicted labels with maximum probability\n        label_size = labels.size(0)   # Get the number of labels in the current batch\n        total += label_size   # Update total count of predictions\n        correct += (predicted == labels).sum().item()   # Update count of correct predictions by summing up correct predictions in the current batch\n\naccuracy = 100 * correct / total   # Calculate accuracy by dividing correct predictions by total predictions and multiplying by 100 to get percentage\n\nprint(f'Accuracy of the network on test images: {accuracy:.3}%')","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:18:09.529066Z","iopub.execute_input":"2023-04-16T19:18:09.529468Z","iopub.status.idle":"2023-04-16T19:18:11.619656Z","shell.execute_reply.started":"2023-04-16T19:18:09.529430Z","shell.execute_reply":"2023-04-16T19:18:11.618289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we observe, our model achieves an accuracy of 99.1% on the test images.","metadata":{}},{"cell_type":"markdown","source":"# Classification Observations\nLet us also view some of the classifications our model performs on the test data.","metadata":{}},{"cell_type":"code","source":"net.eval()   # Set the model to evaluation mode, which disables dropout and batch normalization\n\nnum_images = 5   # Number of images to visualize\n\nwith torch.no_grad():   # Disable gradient computation for efficiency\n    for data in test_loader:   # Loop through the test dataset\n        images, labels = data   # Get images and labels from the test dataset\n        images = images.to(device)   # Move images to the specified device (e.g., GPU or CPU)\n        labels = labels.to(device)   # Move labels to the specified device\n\n        outputs = net(images.float())   # Forward pass to get predicted outputs from the model\n        predictions = torch.argmax(outputs, dim=1)   # Get predicted labels with maximum probability\n\n        for i in range(data[0].shape[0]):   # Loop through the images in the current batch\n            pred = predictions[i].item()   # Get the predicted label for the current image\n            label = labels[i]   # Get the actual label for the current image\n            if(num_images > 0):   # Check if the number of images to visualize is greater than 0\n                print(f'Actual Label: {pred}, Predicted Label: {label}')   # Print the actual and predicted label for the current image\n                img = np.reshape(images[i].cpu().numpy(),[1,28,28])   # Convert the image tensor to a NumPy array and reshape it to [1, 28, 28] size\n                visualize_image(img)   # Visualize the image using a custom function (e.g., visualize_image)\n                num_images -= 1   # Decrement the number of images to visualize by 1\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:18:11.621259Z","iopub.execute_input":"2023-04-16T19:18:11.622300Z","iopub.status.idle":"2023-04-16T19:18:14.098128Z","shell.execute_reply.started":"2023-04-16T19:18:11.622224Z","shell.execute_reply":"2023-04-16T19:18:14.096871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting training logs\nTo further understand and analyse the training of our model, let us plot the training logs for loss and accuracy.","metadata":{}},{"cell_type":"code","source":"fig, ax1 = plt.subplots()   # Create a figure with a single subplot and return the figure object and axes object\n\nplt.title(\"Accuracy & Loss vs Epoch\")   # Set the title of the plot\n\nax2 = ax1.twinx()   # Create a twin y-axis on the right side of the plot\n\nax1.plot(epoch_log, loss_log, 'g-')   # Plot the epoch vs loss with green color\nax2.plot(epoch_log, accuracy_log, 'b-')   # Plot the epoch vs test accuracy with blue color on the twin y-axis\n\nax1.set_xlabel('Epochs')   # Set the x-axis label to 'Epochs'\nax1.set_ylabel('Loss', color='g')   # Set the left y-axis label to 'Loss' with green color\nax2.set_ylabel('Test Accuracy', color='b')   # Set the right y-axis label to 'Test Accuracy' with blue color\n\nplt.show()   # Display the plot\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:18:14.099977Z","iopub.execute_input":"2023-04-16T19:18:14.100726Z","iopub.status.idle":"2023-04-16T19:18:14.407688Z","shell.execute_reply.started":"2023-04-16T19:18:14.100680Z","shell.execute_reply":"2023-04-16T19:18:14.406616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations: As the Number of Epochs increases i.e number of times you run the dataset through model, test accuracy increases and loss decreases","metadata":{}},{"cell_type":"markdown","source":"# Plotting Confusion Matrix\nLastly, let us plot the confusion matrix to evaluate the classwise performance of our model and understand where it can do better.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:18:14.413118Z","iopub.execute_input":"2023-04-16T19:18:14.413544Z","iopub.status.idle":"2023-04-16T19:18:14.670843Z","shell.execute_reply.started":"2023-04-16T19:18:14.413506Z","shell.execute_reply":"2023-04-16T19:18:14.669528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_list = torch.zeros(0, dtype=torch.long, device='cpu')   # Create an empty tensor to store predicted labels with dtype long and device CPU\nlabel_list = torch.zeros(0, dtype=torch.long, device='cpu')   # Create an empty tensor to store actual labels with dtype long and device CPU\n\nwith torch.no_grad():   # Turn off gradient computation during inference\n    for i, (inputs, classes) in enumerate(test_loader):   # Iterate over the test data loader\n        inputs = inputs.to(device)   # Move inputs to the specified device (e.g., CPU or GPU)\n        classes = classes.to(device)   # Move actual labels to the specified device\n        outputs = net(inputs.float())   # Pass inputs through the network to get predicted outputs\n        _, preds = torch.max(outputs, 1)   # Get the predicted labels by finding the indices of maximum values along the second dimension (class probabilities)\n\n        pred_list = torch.cat([pred_list, preds.view(-1).cpu()])   # Concatenate predicted labels to the pred_list tensor, reshaping to 1D and moving to CPU\n        label_list = torch.cat([label_list, classes.view(-1).cpu()])   # Concatenate actual labels to the label_list tensor, reshaping to 1D and moving to CPU\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:21:55.344740Z","iopub.execute_input":"2023-04-16T19:21:55.345254Z","iopub.status.idle":"2023-04-16T19:21:57.443820Z","shell.execute_reply.started":"2023-04-16T19:21:55.345197Z","shell.execute_reply":"2023-04-16T19:21:57.442492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nFurther, let us visualise this confusion matrix.","metadata":{}},{"cell_type":"code","source":"conf_mat = confusion_matrix(label_list.numpy(), pred_list.numpy())   # Compute the confusion matrix using predicted and actual labels converted to NumPy arrays\nclass_names = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)   # Define the class names as a tuple of integers from 0 to 9\ndataframe = pd.DataFrame(conf_mat, index=class_names, columns=class_names)   # Create a DataFrame from the confusion matrix, with class names as row and column indices\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:22:41.542697Z","iopub.execute_input":"2023-04-16T19:22:41.543576Z","iopub.status.idle":"2023-04-16T19:22:41.552880Z","shell.execute_reply.started":"2023-04-16T19:22:41.543532Z","shell.execute_reply":"2023-04-16T19:22:41.551322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n \nplt.title(\"Confusion Matrix\"), plt.tight_layout()\n \nplt.ylabel(\"True Class\"), \nplt.xlabel(\"Predicted Class\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-16T19:22:43.953536Z","iopub.execute_input":"2023-04-16T19:22:43.953942Z","iopub.status.idle":"2023-04-16T19:22:44.659413Z","shell.execute_reply.started":"2023-04-16T19:22:43.953909Z","shell.execute_reply":"2023-04-16T19:22:44.658257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Observations:\n\nHe we infer that , 558 times the label was 0 and our model predicted it as 0.Similarly 567 times label was 1 and and model predicted 1. Highest value is 4 , which means four times the label was 8 (True class) and our model predicted it 3, which is considered as error. ","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\n\n- The accuracy on test test is 99.1% which is really good for CNN\n- CNNs, or Convolutional Neural Networks, are specialized neural networks for processing data with a known grid-like topology, such as images or time-series data.\n- CNNs consist of convolutional layers, pooling layers, and fully connected layers, and are commonly used in computer vision and other areas of deep learning.\n- Convolutional layers perform convolution on the input data to extract local patterns or features.\n- Pooling layers downsample the spatial dimensions of the data while preserving important features.\n- Activation functions, such as ReLU, sigmoid, and tanh, introduce non-linearity into the network.\n- We have successfully created a  CNN model using Pytorch.","metadata":{}},{"cell_type":"markdown","source":"# References\n- https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939\n- https://www.youtube.com/watch?v=iqQgED9vV7k\n- https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel","metadata":{}}]}